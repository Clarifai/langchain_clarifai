{
 "cells": [
  {
   "cell_type": "raw",
   "id": "afaf8039",
   "metadata": {},
   "source": [
    "---\n",
    "sidebar_label: Clarifai\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49f1e0d",
   "metadata": {},
   "source": [
    "# ChatClarifai\n",
    "\n",
    "This will help you getting started with Clarifai [chat models](/docs/concepts/chat_models). For detailed documentation of all ChatClarifai features and configurations head to the [API reference](https://python.langchain.com/api_reference/clarifai/chat_models/langchain_clarifai.chat_models.ChatClarifai.html).\n",
    "\n",
    "- [Clarifai docs](https://docs.clarifai.com/)\n",
    "\n",
    "## Overview\n",
    "### Integration details\n",
    "\n",
    "| Class | Package | Local | Serializable | Package downloads | Package latest |\n",
    "| :--- | :--- | :---: | :---: |  :---: | :---: |\n",
    "| [ChatClarifai](https://python.langchain.com/api_reference/clarifai/chat_models/langchain_clarifai.chat_models.ChatClarifai.html) | [langchain-clarifai](https://python.langchain.com/api_reference/clarifai/) | ✅/❌ | beta/❌ | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-clarifai?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-clarifai?style=flat-square&label=%20) |\n",
    "\n",
    "### Model features\n",
    "| [Tool calling](/docs/how_to/tool_calling) | [Structured output](/docs/how_to/structured_output/) | JSON mode | [Image input](/docs/how_to/multimodal_inputs/) | Audio input | Video input | [Token-level streaming](/docs/how_to/chat_streaming/) | Native async | [Token usage](/docs/how_to/chat_token_usage_tracking/) | [Logprobs](/docs/how_to/logprobs/) |\n",
    "| :---: | :---: | :---: | :---: |  :---: | :---: | :---: | :---: | :---: | :---: |\n",
    "| ✅ | ✅| ✅ | ✅ | ✅/❌ | ✅/❌ | ✅/❌ | ✅/❌ | ✅/❌ | ✅/❌ | \n",
    "\n",
    "## Setup\n",
    "\n",
    "To access Clarifai models you'll need to create a/an Clarifai account, get an API key, and install the `langchain-clarifai` integration package.\n",
    "\n",
    "### Credentials\n",
    "\n",
    "Head to https://www.clarifai.com/ to sign up to Clarifai and generate an API key. Once you've done this set the CLARIFAI_PAT environment variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433e8d2b-9519-4b49-b2c4-7ab65b046c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"CLARIFAI_PAT\"):\n",
    "    os.environ[\"CLARIFAI_PAT\"] = getpass.getpass(\"Enter your Clarifai PAT: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ee0c4b-9764-423a-9dbf-95129e185210",
   "metadata": {},
   "source": [
    "If you want to get automated tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15d341e-3e26-4ca3-830b-5aab30ed66de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0730d6a1-c893-4840-9817-5e5251676d5d",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "The LangChain Clarifai integration lives in the `langchain-clarifai` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652d6238-1f87-422a-b135-f5abbb8652fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-clarifai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38cde65-254d-4219-a441-068766c0d4b5",
   "metadata": {},
   "source": [
    "## Instantiation\n",
    "\n",
    "Now we can instantiate our model object and generate chat completions:\n",
    "\n",
    "- TODO: Update model instantiation with relevant params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb09c344-1836-4e0c-acf8-11d13ac1dbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_clarifai import ChatClarifai\n",
    "\n",
    "llm = ChatClarifai(\n",
    "    model_url=\"https://clarifai.com/openai/chat-completion/models/gpt-4_1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4f3e15",
   "metadata": {},
   "source": [
    "## Invocation\n",
    "\n",
    "- TODO: Run cells so output can be seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e0dbc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86145b3-bfef-46e8-b227-4dda5c9c2705",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e2bfc0-7e78-4528-a73f-499ac150dca8",
   "metadata": {},
   "source": [
    "## Chaining\n",
    "\n",
    "We can [chain](/docs/how_to/sequence/) our model with a prompt template like so:\n",
    "\n",
    "- TODO: Run cells so output can be seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e197d1d7-a070-4c96-9f8a-a0e86d046e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that translates {input_language} to {output_language}.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"input_language\": \"English\",\n",
    "        \"output_language\": \"German\",\n",
    "        \"input\": \"I love programming.\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9e4ada5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'GetWeather',\n",
       "  'args': {'location': 'Los Angeles, CA'},\n",
       "  'id': 'call_lOZEtKoTJBUsoTl3sge9tT7N',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'GetWeather',\n",
       "  'args': {'location': 'New York, NY'},\n",
       "  'id': 'call_3bzMWKXBw0aVencv9htHLMvU',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'GetPopulation',\n",
       "  'args': {'location': 'Los Angeles, CA'},\n",
       "  'id': 'call_cSQfuTCpzdnGqhVfnDm6nTt5',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'GetPopulation',\n",
       "  'args': {'location': 'New York, NY'},\n",
       "  'id': 'call_rueCbvMiFeqBStl1GNkqKbWi',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class GetWeather(BaseModel):\n",
    "    '''Get the current weather in a given location'''\n",
    "\n",
    "    location: str = Field(..., description=\"The city and state, e.g. San Francisco, CA\")\n",
    "\n",
    "class GetPopulation(BaseModel):\n",
    "    '''Get the current population in a given location'''\n",
    "\n",
    "    location: str = Field(..., description=\"The city and state, e.g. San Francisco, CA\")\n",
    "\n",
    "llm_with_tools = llm.bind_tools([GetWeather, GetPopulation])\n",
    "ai_msg = llm_with_tools.invoke(\"Which city is hotter today and which is bigger: LA or NY?\")\n",
    "ai_msg.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a0b710d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup='Why was the cat sitting on the computer?', punchline='Because it wanted to keep an eye on the mouse!', rating=7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    '''Joke to tell user.'''\n",
    "\n",
    "    setup: str = Field(description=\"The setup of the joke\")\n",
    "    punchline: str = Field(description=\"The punchline to the joke\")\n",
    "    rating: Optional[int] = Field(description=\"How funny the joke is, from 1 to 10\")\n",
    "\n",
    "structured_llm = llm.with_structured_output(Joke)\n",
    "structured_llm.invoke(\"Tell me a joke about cats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ee55bc-ffc8-4cfa-801c-993953a08cfd",
   "metadata": {},
   "source": [
    "## TODO: Any functionality specific to this model provider\n",
    "\n",
    "E.g. creating/using finetuned models via this provider. Delete if not relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5bb5ca-c3ae-4a58-be67-2cd18574b9a3",
   "metadata": {},
   "source": [
    "## API reference\n",
    "\n",
    "For detailed documentation of all ChatClarifai features and configurations head to the [API reference](https://python.langchain.com/api_reference/clarifai/chat_models/langchain_clarifai.chat_models.ChatClarifai.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
